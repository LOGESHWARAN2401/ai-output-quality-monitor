# Automated AI Output Quality Monitor

## Overview
This project evaluates AI-generated responses across different configurations.
It measures response quality, latency, and cost without making automated decisions.

## Metrics Used
- Response length consistency
- Uncertainty language detection
- Latency and cost tracking

## How to Run
```bash
pip install -r requirements.txt
python run_evaluation.py
